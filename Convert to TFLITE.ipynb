{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model = tf.keras.models.load_model('acc_gyro_LSTM9.h5')\n",
    "checkpoint_path = \"trainingAG_LSTM_FINAL9/cp.ckpt\"\n",
    "LSTM_model.load_weights(checkpoint_path)\n",
    "\n",
    "run_model = tf.function(lambda x: LSTM_model(x))\n",
    "# This is important, let's fix the input size.\n",
    "BATCH_SIZE = 1\n",
    "STEPS = 30\n",
    "INPUT_SIZE = 6\n",
    "concrete_func = run_model.get_concrete_function(\n",
    "    tf.TensorSpec([BATCH_SIZE, STEPS, INPUT_SIZE], LSTM_model.inputs[0].dtype))\n",
    "\n",
    "# model directory.\n",
    "MODEL_DIR = \"keras_lstm9\"\n",
    "LSTM_model.save(MODEL_DIR, save_format=\"tf\", signatures=concrete_func)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-5700</th>\n",
       "      <th>6888</th>\n",
       "      <th>12384</th>\n",
       "      <th>420</th>\n",
       "      <th>-5707</th>\n",
       "      <th>-1692</th>\n",
       "      <th>-5980</th>\n",
       "      <th>6384</th>\n",
       "      <th>12776</th>\n",
       "      <th>794</th>\n",
       "      <th>...</th>\n",
       "      <th>1594</th>\n",
       "      <th>-8823</th>\n",
       "      <th>-4679</th>\n",
       "      <th>-2184</th>\n",
       "      <th>14992</th>\n",
       "      <th>1132</th>\n",
       "      <th>1294</th>\n",
       "      <th>-4062</th>\n",
       "      <th>-1328</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5980</td>\n",
       "      <td>6384</td>\n",
       "      <td>12776</td>\n",
       "      <td>794</td>\n",
       "      <td>-1036</td>\n",
       "      <td>-1222</td>\n",
       "      <td>-7348</td>\n",
       "      <td>7424</td>\n",
       "      <td>13836</td>\n",
       "      <td>730</td>\n",
       "      <td>...</td>\n",
       "      <td>1294</td>\n",
       "      <td>-4062</td>\n",
       "      <td>-1328</td>\n",
       "      <td>-1380</td>\n",
       "      <td>18304</td>\n",
       "      <td>1952</td>\n",
       "      <td>-906</td>\n",
       "      <td>-2616</td>\n",
       "      <td>1565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7348</td>\n",
       "      <td>7424</td>\n",
       "      <td>13836</td>\n",
       "      <td>730</td>\n",
       "      <td>-2235</td>\n",
       "      <td>389</td>\n",
       "      <td>-5584</td>\n",
       "      <td>6744</td>\n",
       "      <td>13868</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>-906</td>\n",
       "      <td>-2616</td>\n",
       "      <td>1565</td>\n",
       "      <td>-1512</td>\n",
       "      <td>16124</td>\n",
       "      <td>2680</td>\n",
       "      <td>-753</td>\n",
       "      <td>2345</td>\n",
       "      <td>2680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5584</td>\n",
       "      <td>6744</td>\n",
       "      <td>13868</td>\n",
       "      <td>109</td>\n",
       "      <td>-2177</td>\n",
       "      <td>-1112</td>\n",
       "      <td>-6224</td>\n",
       "      <td>6480</td>\n",
       "      <td>14060</td>\n",
       "      <td>-137</td>\n",
       "      <td>...</td>\n",
       "      <td>-753</td>\n",
       "      <td>2345</td>\n",
       "      <td>2680</td>\n",
       "      <td>-1576</td>\n",
       "      <td>14240</td>\n",
       "      <td>1920</td>\n",
       "      <td>-1713</td>\n",
       "      <td>550</td>\n",
       "      <td>3010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6224</td>\n",
       "      <td>6480</td>\n",
       "      <td>14060</td>\n",
       "      <td>-137</td>\n",
       "      <td>1387</td>\n",
       "      <td>593</td>\n",
       "      <td>-6492</td>\n",
       "      <td>6288</td>\n",
       "      <td>13244</td>\n",
       "      <td>941</td>\n",
       "      <td>...</td>\n",
       "      <td>-1713</td>\n",
       "      <td>550</td>\n",
       "      <td>3010</td>\n",
       "      <td>-932</td>\n",
       "      <td>14812</td>\n",
       "      <td>2484</td>\n",
       "      <td>-1549</td>\n",
       "      <td>989</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6492</td>\n",
       "      <td>6288</td>\n",
       "      <td>13244</td>\n",
       "      <td>941</td>\n",
       "      <td>-1288</td>\n",
       "      <td>-1612</td>\n",
       "      <td>-6760</td>\n",
       "      <td>6200</td>\n",
       "      <td>13648</td>\n",
       "      <td>421</td>\n",
       "      <td>...</td>\n",
       "      <td>-1549</td>\n",
       "      <td>989</td>\n",
       "      <td>1968</td>\n",
       "      <td>-1524</td>\n",
       "      <td>16360</td>\n",
       "      <td>2480</td>\n",
       "      <td>-677</td>\n",
       "      <td>3366</td>\n",
       "      <td>3260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   -5700  6888  12384  420  -5707  -1692  -5980  6384  12776  794  ...  1594  \\\n",
       "0  -5980  6384  12776  794  -1036  -1222  -7348  7424  13836  730  ...  1294   \n",
       "1  -7348  7424  13836  730  -2235    389  -5584  6744  13868  109  ...  -906   \n",
       "2  -5584  6744  13868  109  -2177  -1112  -6224  6480  14060 -137  ...  -753   \n",
       "3  -6224  6480  14060 -137   1387    593  -6492  6288  13244  941  ... -1713   \n",
       "4  -6492  6288  13244  941  -1288  -1612  -6760  6200  13648  421  ... -1549   \n",
       "\n",
       "   -8823  -4679  -2184  14992  1132  1294  -4062  -1328  0  \n",
       "0  -4062  -1328  -1380  18304  1952  -906  -2616   1565  0  \n",
       "1  -2616   1565  -1512  16124  2680  -753   2345   2680  0  \n",
       "2   2345   2680  -1576  14240  1920 -1713    550   3010  0  \n",
       "3    550   3010   -932  14812  2484 -1549    989   1968  0  \n",
       "4    989   1968  -1524  16360  2480  -677   3366   3260  0  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataAccelGyroX3.txt')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the points and the labels\n",
    "X = dataset.iloc[:, :-1].values  \n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(625060, 30, 6)\n",
      "(156266, 30, 6)\n",
      "[[ -6884  11255   8449  -3805   1157   -203]\n",
      " [ -7854   8611  10340  -6159   -342   -748]\n",
      " [ -8707  11575  11793  -2660   2003  -1902]\n",
      " [ -5764   6920  12700  -2775   3429  -2854]\n",
      " [ -6005   6389  15372   3006   1255  -3440]\n",
      " [ -3306   6752  15499   2562    539  -1897]\n",
      " [ -3363   8443  13615   3292   1473   1931]\n",
      " [ -6249   8837  11193   4661  -4737   -229]\n",
      " [ -9218  10061   9085     99  -4329   4200]\n",
      " [ -8857   8494  10835  -5377  -1926   6476]\n",
      " [-10460  10598  13220  -3851  -3268   5701]\n",
      " [ -9042   9105  12321  -1343  -1182   3301]\n",
      " [ -6590  10870  12248  -2657  11085   7632]\n",
      " [ -7516   8130  10365   1441   8280   3934]\n",
      " [ -6227  10810   8100  -3903  10955   5164]\n",
      " [ -5991   9998  11717  -5563   9192   3448]\n",
      " [ -3013  10184  10585    585   4078    182]\n",
      " [ -2774  10222   9542   3192   2880  -3629]\n",
      " [ -7940   9365  11836   2269     88   -996]\n",
      " [ -4454  11921  10069   2280  -2039  -2983]\n",
      " [ -7601   8610  11251   6194 -13753  -5437]\n",
      " [ -8451  12010   8679   1370 -12665  -1159]\n",
      " [ -6384  11801   9171  -3298 -14538   2974]\n",
      " [ -2308   7082   8288  -6033 -16009   2047]\n",
      " [ -5049   7827  11490  -5020  -9974  -5406]\n",
      " [ -2871  -6057   5203  20156 -13024 -24840]\n",
      " [  7067  -2244  -6367   6155 -34067 -17666]\n",
      " [  -524   4507  -5973   -885 -25254  15897]\n",
      " [-14178  22796  19500 -10899   9931  41823]\n",
      " [  1712  20300   6954    206  21025  19548]]\n"
     ]
    }
   ],
   "source": [
    "window = 30 # depends on time window\n",
    "epochs = 15\n",
    "batch_size = 256\n",
    "acc_vec_dim = 6 # depends on how many sensors used\n",
    "\n",
    "class_names = list(set(y))\n",
    "num_class = len(class_names)\n",
    "\n",
    "X_testg = X_test.reshape(X_test.shape[0], window, acc_vec_dim)\n",
    "X_traing = X_train.reshape(X_train.shape[0], window, acc_vec_dim)\n",
    "print(X_traing.shape)\n",
    "print(X_testg.shape)\n",
    "print(X_traing[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(X_testg, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_data(input_data).npy', 'wb') as f:\n",
    "    np.save(f, input_data)\n",
    "    \n",
    "with open('test_data(y_test).npy', 'wb') as g:\n",
    "    np.save(g, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SINIIIIIIIIIIIIIIIIIIIIIIIIII\n",
    "with open('test_data(input_data)9.npy', 'rb') as f:\n",
    "    input_data = np.load(f)\n",
    "    \n",
    "with open('test_data(y_test)9.npy', 'rb') as g:\n",
    "    y_test = np.load(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "   Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_predict_function_43615]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-84ead0914672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mexpected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mnormal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m    129\u001b[0m           method.__name__))\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1597\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    844\u001b[0m               *args, **kwds)\n\u001b[0;32m    845\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 846\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:    Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_predict_function_43615]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "# Run the model with TensorFlow to get expected results.\n",
    "TEST_CASES = 1000\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "normal = []\n",
    "tflite = []\n",
    "same = 0\n",
    "for i in range(TEST_CASES):\n",
    "    try:\n",
    "        t = time.time()\n",
    "        expected = LSTM_model.predict(input_data[i:i+1])\n",
    "        normal.append(time.time() - t)\n",
    "        t = time.time()\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], input_data[i:i+1, :, :])\n",
    "        interpreter.invoke()\n",
    "        result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "        tflite.append(time.time() - t)\n",
    "        \n",
    "        interpreter.reset_all_variables()\n",
    "\n",
    "        # Assert if the result of TFLite model is consistent with the TF model.\n",
    "        np.testing.assert_almost_equal(expected, result)\n",
    "        #print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "        same += 1\n",
    "\n",
    "        # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "        # the states.\n",
    "        # Clean up internal states.\n",
    "        #interpreter.reset_all_variables()\n",
    "    except AssertionError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "\n",
    "for i in range(TEST_CASES, TEST_CASES*2):\n",
    "    try:\n",
    "        \n",
    "        t = time.time()\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], input_data[i:i+1, :, :])\n",
    "        interpreter.invoke()\n",
    "        result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "        tflite.append(time.time() - t)\n",
    "        \n",
    "        t = time.time()\n",
    "        expected = LSTM_model.predict(input_data[i:i+1])\n",
    "        normal.append(time.time() - t)\n",
    "        \n",
    "        interpreter.reset_all_variables()\n",
    "\n",
    "        # Assert if the result of TFLite model is consistent with the TF model.\n",
    "        np.testing.assert_almost_equal(expected, result)\n",
    "        #print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "        same += 1\n",
    "\n",
    "        # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "        # the states.\n",
    "        # Clean up internal states.\n",
    "        #interpreter.reset_all_variables()\n",
    "    except AssertionError as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "\n",
    "print(f\"Same: {same}\")\n",
    "total = 0\n",
    "for value in normal:\n",
    "    total += value\n",
    "    \n",
    "total = total/len(normal)\n",
    "print(f\"Normal: {total}\")\n",
    "\n",
    "total = 0\n",
    "for value in tflite:\n",
    "    total += value\n",
    "    \n",
    "total = total/len(tflite)\n",
    "print(f\"TFLITE: {total}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[14:15].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_details[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -2384.,  16660.,   1868.,   2875.,   5435.,   7369.],\n",
       "        [ -2160.,  21632.,   1320.,   3000.,   6167.,   6307.],\n",
       "        [ -2844.,  16408.,   2404.,   3542.,   7324.,   6017.],\n",
       "        [ -2356.,  11828.,   1412.,   1814.,   1690.,   2944.],\n",
       "        [ -2116.,  17960.,     48.,  -1075.,   5847.,   2145.],\n",
       "        [ -2392.,  15232.,    256.,  -1711.,  15084.,    560.],\n",
       "        [ -2760.,  14816.,    728.,   -769.,  11125.,  -2087.],\n",
       "        [ -4656.,  15252.,    600.,   -653.,   7321.,  -3107.],\n",
       "        [ -5700.,  14840.,    848.,  -1095.,   8354.,  -2022.],\n",
       "        [ -6144.,  13160.,   1700.,  -1672.,   3973.,  -1570.],\n",
       "        [ -6800.,  13356.,   2004.,  -1512.,   3831.,  -2308.],\n",
       "        [-10580.,  12680.,   1536.,  -1066.,   5263.,   -784.],\n",
       "        [ -9428.,  15680.,   1656.,  -1158.,    261.,    440.],\n",
       "        [ -5520.,  14880.,   1812.,   -673.,    -82.,  -4973.],\n",
       "        [ -9736.,  14776.,   2324.,   1766.,  -2742.,  -7363.],\n",
       "        [ -8828.,  13952.,   1204.,   3124.,  -7985.,  -7311.],\n",
       "        [ -8396.,  11684.,    724.,   3614.,  -9844.,  -5332.],\n",
       "        [ -6896.,  12172.,    596.,   2664.,  -7475.,    107.],\n",
       "        [ -5404.,  12696.,    804.,   2787.,  -3968.,   2976.],\n",
       "        [ -5264.,  14432.,   1232.,   2656.,  -3763.,   5682.],\n",
       "        [ -4868.,  19684.,    640.,   2141.,  -4819.,   6903.],\n",
       "        [ -3764.,  19996.,    688.,   2343.,   2754.,   9219.],\n",
       "        [ -1852.,  14496.,   1516.,   2538.,   5655.,   6672.],\n",
       "        [ -1020.,  14700.,    536.,    430.,   2622.,   1820.],\n",
       "        [ -1560.,  16448.,    420.,  -1395.,  12883.,    713.],\n",
       "        [ -4300.,  14340.,   1492.,    -23.,  13899.,   1445.],\n",
       "        [ -5484.,  14444.,   1928.,    112.,   5714.,   1533.],\n",
       "        [ -5928.,  15104.,   2148.,  -1354.,   4754.,      0.],\n",
       "        [ -7720.,  13804.,   2348.,  -2613.,   8661.,  -1259.],\n",
       "        [ -8472.,  13344.,   2844.,  -2646.,   6274.,  -2651.]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[i:i+1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model2 = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Did not get operators, tensors, or buffers in subgraph 1.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0f97ece7dbba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Run the model with TensorFlow Lite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtflite_model2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0minput_details\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_input_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AllPython\\Anaconda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_content, experimental_delegates, num_threads)\u001b[0m\n\u001b[0;32m    206\u001b[0m       self._interpreter = (\n\u001b[0;32m    207\u001b[0m           _interpreter_wrapper.CreateWrapperFromBuffer(\n\u001b[1;32m--> 208\u001b[1;33m               model_content, self._custom_op_registerers))\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_content\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`model_path` or `model_content` must be specified.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Did not get operators, tensors, or buffers in subgraph 1.\n"
     ]
    }
   ],
   "source": [
    "# Run the model with TensorFlow to get expected results.\n",
    "TEST_CASES = 10\n",
    "\n",
    "# Run the model with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model2)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "for i in range(TEST_CASES):\n",
    "    try:\n",
    "        expected = LSTM_model.predict(input_data[i:i+1])\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], input_data[i:i+1, :, :])\n",
    "        interpreter.invoke()\n",
    "        result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "        # Assert if the result of TFLite model is consistent with the TF model.\n",
    "        np.testing.assert_almost_equal(expected, result)\n",
    "        print(\"Done. The result of TensorFlow matches the result of TensorFlow Lite.\")\n",
    "\n",
    "        # Please note: TfLite fused Lstm kernel is stateful, so we need to reset\n",
    "        # the states.\n",
    "        # Clean up internal states.\n",
    "        interpreter.reset_all_variables()\n",
    "    except AssertionError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with TensorFlow Lite\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_details[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for i in range(0,1000,3):\n",
    "    interpreter.set_tensor(input_details[0][\"index\"], input_data[i:i+3, :, :])\n",
    "    interpreter.invoke()\n",
    "    result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "    prediction.append(np.argmax(result[0]))\n",
    "    prediction.append(np.argmax(result[1]))\n",
    "    prediction.append(np.argmax(result[2]))\n",
    "    interpreter.reset_all_variables()\n",
    "    \n",
    "accurate_count = 0\n",
    "for index in range(len(prediction)):\n",
    "    if prediction[index] == y_test[index]:\n",
    "        accurate_count += 1\n",
    "accuracy = accurate_count * 1.0 / len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93812375249501\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"tflite_LSTM.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 30, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[i:i+3, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9990237e-01 1.4385454e-10 9.7083503e-05 6.1384912e-07]\n",
      " [1.6832739e-05 2.0929762e-04 9.9419832e-01 5.5755591e-03]\n",
      " [9.9999785e-01 1.4478806e-13 9.4301823e-11 2.1306262e-06]]\n",
      "0\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "interpreter.set_tensor(input_details[0][\"index\"], input_data[0:3, :, :])\n",
    "interpreter.invoke()\n",
    "result = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "print(result)\n",
    "print(np.argmax(result[0]))\n",
    "print(np.argmax(result[1]))\n",
    "print(np.argmax(result[2]))\n",
    "prediction.append(np.argmax(result))\n",
    "interpreter.reset_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf2gpu] *",
   "language": "python",
   "name": "conda-env-tf2gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
